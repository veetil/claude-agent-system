# Step 5: Orchestrator and Multi-Agent Coordination

## Overview
Implement the Orchestrator that manages multiple agents, coordinates complex workflows, and provides various communication patterns (sequential, parallel, pipeline, hierarchical).

## Objectives
1. Build the Orchestrator with agent management
2. Implement multiple communication patterns
3. Create task distribution and result aggregation
4. Add workflow templates and patterns
5. Test multi-agent coordination thoroughly

## Implementation Tasks

### 1. Core Orchestrator Implementation
```python
# src/orchestrator/core.py
import asyncio
import logging
from typing import Dict, List, Optional, Any, Callable, Union
from pathlib import Path
from dataclasses import dataclass
from enum import Enum

from src.agent.core import Agent
from src.agent.factory import AgentBuilder
from src.agent.pool import AgentPool
from src.core.types import AgentConfig, TaskInput
from src.workspace.manager import WorkspaceManager
from src.session.manager import SessionManager

logger = logging.getLogger(__name__)

class WorkflowPattern(Enum):
    SEQUENTIAL = "sequential"
    PARALLEL = "parallel"
    PIPELINE = "pipeline"
    HIERARCHICAL = "hierarchical"
    BROADCAST = "broadcast"
    ROUND_ROBIN = "round_robin"

@dataclass
class WorkflowResult:
    """Result of a workflow execution"""
    pattern: WorkflowPattern
    agents: List[str]
    results: Dict[str, Any]
    metadata: Dict[str, Any]
    success: bool
    errors: List[str]

class Orchestrator:
    """Manages multiple agents and coordinates workflows"""
    
    def __init__(
        self,
        base_dir: Optional[Path] = None,
        max_agents: int = 10
    ):
        self.base_dir = base_dir or Path("/tmp/claude-orchestrator")
        self.agents: Dict[str, Agent] = {}
        self.agent_pool = AgentPool(max_agents)
        self.workspace_manager = WorkspaceManager(self.base_dir)
        self.session_manager = SessionManager(self.base_dir / "sessions")
        self._lock = asyncio.Lock()
        
    async def create_agent(
        self,
        agent_id: str,
        system_prompt: str,
        **kwargs
    ) -> Agent:
        """Create and register a new agent"""
        async with self._lock:
            if agent_id in self.agents:
                logger.warning(f"Agent {agent_id} already exists")
                return self.agents[agent_id]
                
            # Build agent config
            builder = (
                AgentBuilder()
                .with_id(agent_id)
                .with_system_prompt(system_prompt)
                .with_workspace_manager(self.workspace_manager)
            )
            
            # Apply additional configurations
            if "allowed_tools" in kwargs:
                builder.with_allowed_tools(kwargs["allowed_tools"])
            if "max_turns" in kwargs:
                builder.with_max_turns(kwargs["max_turns"])
                
            agent = builder.build()
            await agent.initialize()
            
            self.agents[agent_id] = agent
            logger.info(f"Created agent: {agent_id}")
            
            return agent
            
    async def get_agent(self, agent_id: str) -> Optional[Agent]:
        """Get agent by ID"""
        return self.agents.get(agent_id)
        
    async def remove_agent(self, agent_id: str):
        """Remove and cleanup agent"""
        async with self._lock:
            if agent_id not in self.agents:
                logger.warning(f"Agent {agent_id} not found")
                return
                
            agent = self.agents[agent_id]
            await agent.cleanup()
            del self.agents[agent_id]
            
            logger.info(f"Removed agent: {agent_id}")
            
    async def send_task(
        self,
        agent_id: str,
        task: Union[str, TaskInput]
    ) -> str:
        """Send task to specific agent"""
        agent = await self.get_agent(agent_id)
        if not agent:
            raise ValueError(f"Agent {agent_id} not found")
            
        if isinstance(task, str):
            return await agent.ask(task)
        else:
            async with agent.task_context(task):
                return await agent.ask(task.prompt)
                
    async def sequential(
        self,
        agents: List[str],
        task: str,
        transform_fn: Optional[Callable[[str], str]] = None
    ) -> WorkflowResult:
        """Execute task sequentially through agents"""
        results = {}
        errors = []
        current_output = task
        
        for agent_id in agents:
            try:
                # Transform output if function provided
                if transform_fn and agent_id != agents[0]:
                    current_output = transform_fn(current_output)
                    
                result = await self.send_task(agent_id, current_output)
                results[agent_id] = result
                current_output = result
                
            except Exception as e:
                error_msg = f"Agent {agent_id} failed: {e}"
                logger.error(error_msg)
                errors.append(error_msg)
                break
                
        return WorkflowResult(
            pattern=WorkflowPattern.SEQUENTIAL,
            agents=agents,
            results=results,
            metadata={"final_output": current_output},
            success=len(errors) == 0,
            errors=errors
        )
        
    async def parallel(
        self,
        agents: List[str],
        task: str
    ) -> WorkflowResult:
        """Execute task in parallel across agents"""
        tasks = [
            self.send_task(agent_id, task)
            for agent_id in agents
        ]
        
        # Execute all tasks concurrently
        results_list = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Process results
        results = {}
        errors = []
        
        for agent_id, result in zip(agents, results_list):
            if isinstance(result, Exception):
                error_msg = f"Agent {agent_id} failed: {result}"
                errors.append(error_msg)
                results[agent_id] = None
            else:
                results[agent_id] = result
                
        return WorkflowResult(
            pattern=WorkflowPattern.PARALLEL,
            agents=agents,
            results=results,
            metadata={"execution_time": "parallel"},
            success=len(errors) == 0,
            errors=errors
        )
        
    async def pipeline(
        self,
        stages: List[Dict[str, Any]],
        initial_input: str
    ) -> WorkflowResult:
        """Execute pipeline workflow with stages"""
        results = {}
        errors = []
        current_data = initial_input
        
        for stage in stages:
            agent_id = stage["agent"]
            transform = stage.get("transform")
            
            try:
                # Apply transformation if specified
                if transform:
                    if callable(transform):
                        stage_input = transform(current_data)
                    else:
                        stage_input = f"{transform}: {current_data}"
                else:
                    stage_input = current_data
                    
                result = await self.send_task(agent_id, stage_input)
                results[f"stage_{agent_id}"] = result
                current_data = result
                
            except Exception as e:
                error_msg = f"Pipeline stage {agent_id} failed: {e}"
                logger.error(error_msg)
                errors.append(error_msg)
                break
                
        return WorkflowResult(
            pattern=WorkflowPattern.PIPELINE,
            agents=[s["agent"] for s in stages],
            results=results,
            metadata={
                "stages": len(stages),
                "final_output": current_data
            },
            success=len(errors) == 0,
            errors=errors
        )
        
    async def hierarchical(
        self,
        manager_id: str,
        worker_ids: List[str],
        task: str
    ) -> WorkflowResult:
        """Execute hierarchical workflow with manager delegating to workers"""
        results = {"manager": {}, "workers": {}}
        errors = []
        
        try:
            # Manager analyzes and creates subtasks
            manager_prompt = f"""
            Analyze this task and create specific subtasks for workers:
            {task}
            
            You have {len(worker_ids)} workers available.
            Create one specific subtask for each worker.
            Format: "Worker N: [specific subtask]"
            """
            
            manager_response = await self.send_task(manager_id, manager_prompt)
            results["manager"]["delegation"] = manager_response
            
            # Parse subtasks (simple parsing, could be enhanced)
            subtasks = []
            for line in manager_response.split('\n'):
                if line.strip() and ':' in line:
                    subtasks.append(line.split(':', 1)[1].strip())
                    
            # Assign subtasks to workers
            worker_tasks = []
            for worker_id, subtask in zip(worker_ids, subtasks[:len(worker_ids)]):
                worker_tasks.append(self.send_task(worker_id, subtask))
                
            # Execute worker tasks in parallel
            worker_results = await asyncio.gather(*worker_tasks, return_exceptions=True)
            
            # Collect worker results
            for worker_id, result in zip(worker_ids, worker_results):
                if isinstance(result, Exception):
                    errors.append(f"Worker {worker_id} failed: {result}")
                    results["workers"][worker_id] = None
                else:
                    results["workers"][worker_id] = result
                    
            # Manager aggregates results
            aggregation_prompt = f"""
            Aggregate these worker results into a final response:
            {json.dumps(results["workers"], indent=2)}
            
            Original task: {task}
            """
            
            final_result = await self.send_task(manager_id, aggregation_prompt)
            results["manager"]["aggregation"] = final_result
            
        except Exception as e:
            error_msg = f"Hierarchical workflow failed: {e}"
            logger.error(error_msg)
            errors.append(error_msg)
            
        return WorkflowResult(
            pattern=WorkflowPattern.HIERARCHICAL,
            agents=[manager_id] + worker_ids,
            results=results,
            metadata={
                "manager": manager_id,
                "workers": worker_ids
            },
            success=len(errors) == 0,
            errors=errors
        )
        
    async def broadcast(
        self,
        agents: List[str],
        message: str,
        aggregator_fn: Optional[Callable[[List[str]], str]] = None
    ) -> WorkflowResult:
        """Broadcast message to all agents and optionally aggregate"""
        # Send to all agents in parallel
        parallel_result = await self.parallel(agents, message)
        
        # Aggregate if function provided
        if aggregator_fn and parallel_result.success:
            responses = list(parallel_result.results.values())
            aggregated = aggregator_fn(responses)
            parallel_result.metadata["aggregated"] = aggregated
            
        parallel_result.pattern = WorkflowPattern.BROADCAST
        return parallel_result
        
    async def cleanup_all(self):
        """Clean up all agents and resources"""
        agent_ids = list(self.agents.keys())
        
        for agent_id in agent_ids:
            await self.remove_agent(agent_id)
            
        await self.agent_pool.cleanup_all()
        logger.info("Orchestrator cleanup complete")
```

### 2. Workflow Templates
```python
# src/orchestrator/templates.py
from typing import Dict, List, Any
from abc import ABC, abstractmethod

from src.orchestrator.core import Orchestrator, WorkflowResult

class WorkflowTemplate(ABC):
    """Base class for workflow templates"""
    
    def __init__(self, orchestrator: Orchestrator):
        self.orchestrator = orchestrator
        
    @abstractmethod
    async def setup(self):
        """Set up required agents"""
        pass
        
    @abstractmethod
    async def execute(self, task: str) -> WorkflowResult:
        """Execute the workflow"""
        pass

class ResearchWorkflow(WorkflowTemplate):
    """Research workflow: Researcher -> Analyst -> Writer"""
    
    async def setup(self):
        await self.orchestrator.create_agent(
            "researcher",
            "You are a research specialist. Find relevant information and sources."
        )
        await self.orchestrator.create_agent(
            "analyst",
            "You are an analyst. Analyze findings and identify key insights."
        )
        await self.orchestrator.create_agent(
            "writer",
            "You are a technical writer. Create clear, well-structured content."
        )
        
    async def execute(self, task: str) -> WorkflowResult:
        stages = [
            {
                "agent": "researcher",
                "transform": lambda x: f"Research this topic thoroughly: {x}"
            },
            {
                "agent": "analyst",
                "transform": lambda x: f"Analyze these research findings:\n{x}"
            },
            {
                "agent": "writer",
                "transform": lambda x: f"Write a comprehensive report based on:\n{x}"
            }
        ]
        
        return await self.orchestrator.pipeline(stages, task)

class CodeReviewWorkflow(WorkflowTemplate):
    """Code review workflow: parallel review then aggregation"""
    
    async def setup(self):
        await self.orchestrator.create_agent(
            "security_reviewer",
            "You are a security expert. Review code for vulnerabilities."
        )
        await self.orchestrator.create_agent(
            "performance_reviewer",
            "You are a performance expert. Review code for efficiency."
        )
        await self.orchestrator.create_agent(
            "style_reviewer",
            "You are a code style expert. Review for best practices."
        )
        await self.orchestrator.create_agent(
            "lead_reviewer",
            "You are a lead developer. Synthesize review feedback."
        )
        
    async def execute(self, code: str) -> WorkflowResult:
        # Parallel reviews
        review_prompt = f"Review this code:\n```\n{code}\n```"
        
        reviewers = ["security_reviewer", "performance_reviewer", "style_reviewer"]
        parallel_result = await self.orchestrator.parallel(reviewers, review_prompt)
        
        if parallel_result.success:
            # Lead reviewer aggregates
            aggregation_prompt = f"""
            Synthesize these code reviews into actionable feedback:
            
            Security Review: {parallel_result.results['security_reviewer']}
            
            Performance Review: {parallel_result.results['performance_reviewer']}
            
            Style Review: {parallel_result.results['style_reviewer']}
            """
            
            final_review = await self.orchestrator.send_task(
                "lead_reviewer",
                aggregation_prompt
            )
            
            parallel_result.metadata["final_review"] = final_review
            
        return parallel_result

class BrainstormingWorkflow(WorkflowTemplate):
    """Brainstorming workflow: multiple agents generate ideas"""
    
    async def setup(self):
        # Create diverse brainstorming agents
        personas = [
            ("creative_thinker", "You are a creative thinker. Generate innovative, out-of-the-box ideas."),
            ("practical_thinker", "You are practical. Generate feasible, implementable ideas."),
            ("critical_thinker", "You are analytical. Generate well-reasoned, logical ideas."),
            ("visionary_thinker", "You are visionary. Generate forward-thinking, transformative ideas.")
        ]
        
        for agent_id, prompt in personas:
            await self.orchestrator.create_agent(agent_id, prompt)
            
        # Facilitator to synthesize
        await self.orchestrator.create_agent(
            "facilitator",
            "You are a facilitator. Synthesize ideas into a coherent plan."
        )
        
    async def execute(self, topic: str) -> WorkflowResult:
        prompt = f"Brainstorm ideas for: {topic}"
        
        thinkers = [
            "creative_thinker",
            "practical_thinker", 
            "critical_thinker",
            "visionary_thinker"
        ]
        
        # Get ideas from all thinkers
        ideas_result = await self.orchestrator.parallel(thinkers, prompt)
        
        if ideas_result.success:
            # Facilitator synthesizes
            synthesis_prompt = f"""
            Synthesize these brainstorming ideas into a structured plan:
            
            Creative Ideas: {ideas_result.results['creative_thinker']}
            
            Practical Ideas: {ideas_result.results['practical_thinker']}
            
            Critical Analysis: {ideas_result.results['critical_thinker']}
            
            Visionary Ideas: {ideas_result.results['visionary_thinker']}
            
            Create a balanced, actionable plan incorporating the best ideas.
            """
            
            plan = await self.orchestrator.send_task("facilitator", synthesis_prompt)
            ideas_result.metadata["synthesized_plan"] = plan
            
        return ideas_result
```

### 3. Advanced Orchestration Patterns
```python
# src/orchestrator/patterns.py
import asyncio
from typing import List, Dict, Any, Optional
import random

from src.orchestrator.core import Orchestrator, WorkflowResult, WorkflowPattern

class AdvancedPatterns:
    """Advanced orchestration patterns"""
    
    def __init__(self, orchestrator: Orchestrator):
        self.orchestrator = orchestrator
        
    async def map_reduce(
        self,
        data_chunks: List[str],
        mapper_agents: List[str],
        reducer_agent: str,
        map_prompt_template: str = "Process this data: {data}",
        reduce_prompt_template: str = "Combine these results: {results}"
    ) -> WorkflowResult:
        """Map-reduce pattern for distributed processing"""
        # Map phase - distribute chunks to mappers
        map_tasks = []
        
        for i, chunk in enumerate(data_chunks):
            mapper = mapper_agents[i % len(mapper_agents)]
            prompt = map_prompt_template.format(data=chunk)
            map_tasks.append(self.orchestrator.send_task(mapper, prompt))
            
        # Execute mapping in parallel
        map_results = await asyncio.gather(*map_tasks, return_exceptions=True)
        
        # Filter successful results
        successful_results = [
            r for r in map_results 
            if not isinstance(r, Exception)
        ]
        
        # Reduce phase
        reduce_prompt = reduce_prompt_template.format(
            results="\n---\n".join(successful_results)
        )
        
        final_result = await self.orchestrator.send_task(
            reducer_agent,
            reduce_prompt
        )
        
        return WorkflowResult(
            pattern=WorkflowPattern.HIERARCHICAL,
            agents=mapper_agents + [reducer_agent],
            results={
                "map_results": dict(zip(mapper_agents, map_results)),
                "reduce_result": final_result
            },
            metadata={
                "chunks_processed": len(successful_results),
                "total_chunks": len(data_chunks)
            },
            success=len(successful_results) > 0,
            errors=[]
        )
        
    async def consensus(
        self,
        agents: List[str],
        question: str,
        rounds: int = 2
    ) -> WorkflowResult:
        """Multi-round consensus building"""
        all_results = {}
        
        for round_num in range(rounds):
            if round_num == 0:
                # First round - independent opinions
                prompt = question
            else:
                # Subsequent rounds - consider others' opinions
                previous_opinions = "\n".join([
                    f"{agent}: {all_results[f'round_{round_num-1}'][agent]}"
                    for agent in agents
                ])
                
                prompt = f"""
                Question: {question}
                
                Other opinions:
                {previous_opinions}
                
                Considering these perspectives, what is your updated opinion?
                """
                
            # Get opinions from all agents
            round_result = await self.orchestrator.parallel(agents, prompt)
            all_results[f"round_{round_num}"] = round_result.results
            
        # Find consensus
        final_opinions = all_results[f"round_{rounds-1}"]
        
        return WorkflowResult(
            pattern=WorkflowPattern.PARALLEL,
            agents=agents,
            results=all_results,
            metadata={
                "rounds": rounds,
                "final_opinions": final_opinions
            },
            success=True,
            errors=[]
        )
        
    async def tournament(
        self,
        agents: List[str],
        task: str,
        judge_agent: str
    ) -> WorkflowResult:
        """Tournament-style selection of best response"""
        # All agents attempt the task
        responses = await self.orchestrator.parallel(agents, task)
        
        if not responses.success:
            return responses
            
        # Judge evaluates all responses
        evaluation_prompt = f"""
        Task: {task}
        
        Evaluate these responses and select the best one:
        
        {chr(10).join([
            f"Response {i+1} (by {agent}): {response}"
            for i, (agent, response) in enumerate(responses.results.items())
        ])}
        
        Which response is best and why?
        """
        
        judgment = await self.orchestrator.send_task(judge_agent, evaluation_prompt)
        
        responses.metadata["judgment"] = judgment
        return responses
```

### 4. Comprehensive Test Suite
```python
# tests/unit/test_orchestrator.py
import pytest
import asyncio
from unittest.mock import Mock, AsyncMock

from src.orchestrator.core import Orchestrator, WorkflowPattern
from src.orchestrator.templates import ResearchWorkflow

class TestOrchestrator:
    
    @pytest.fixture
    async def orchestrator(self, tmp_path):
        orch = Orchestrator(base_dir=tmp_path)
        yield orch
        await orch.cleanup_all()
        
    @pytest.mark.asyncio
    async def test_create_agent(self, orchestrator):
        agent = await orchestrator.create_agent(
            "test-agent",
            "You are a test agent"
        )
        
        assert agent.id == "test-agent"
        assert agent in orchestrator.agents.values()
        
    @pytest.mark.asyncio
    async def test_sequential_workflow(self, orchestrator):
        # Create agents
        await orchestrator.create_agent("agent1", "First agent")
        await orchestrator.create_agent("agent2", "Second agent")
        
        # Mock responses
        orchestrator.agents["agent1"].ask = AsyncMock(return_value="Result 1")
        orchestrator.agents["agent2"].ask = AsyncMock(return_value="Result 2")
        
        # Execute sequential workflow
        result = await orchestrator.sequential(
            ["agent1", "agent2"],
            "Initial task"
        )
        
        assert result.success
        assert result.pattern == WorkflowPattern.SEQUENTIAL
        assert result.results["agent1"] == "Result 1"
        assert result.results["agent2"] == "Result 2"
        
    @pytest.mark.asyncio
    async def test_parallel_workflow(self, orchestrator):
        # Create agents
        agents = ["agent1", "agent2", "agent3"]
        for agent_id in agents:
            await orchestrator.create_agent(agent_id, f"{agent_id} prompt")
            orchestrator.agents[agent_id].ask = AsyncMock(
                return_value=f"Result from {agent_id}"
            )
            
        # Execute parallel workflow
        result = await orchestrator.parallel(agents, "Parallel task")
        
        assert result.success
        assert result.pattern == WorkflowPattern.PARALLEL
        assert len(result.results) == 3
        assert all(f"Result from {a}" == result.results[a] for a in agents)
        
    @pytest.mark.asyncio
    async def test_pipeline_workflow(self, orchestrator):
        # Create pipeline stages
        await orchestrator.create_agent("preprocessor", "Preprocess data")
        await orchestrator.create_agent("analyzer", "Analyze data")
        await orchestrator.create_agent("reporter", "Generate report")
        
        # Mock responses
        orchestrator.agents["preprocessor"].ask = AsyncMock(
            return_value="Cleaned data"
        )
        orchestrator.agents["analyzer"].ask = AsyncMock(
            return_value="Analysis results"
        )
        orchestrator.agents["reporter"].ask = AsyncMock(
            return_value="Final report"
        )
        
        # Define pipeline
        stages = [
            {"agent": "preprocessor"},
            {"agent": "analyzer"},
            {"agent": "reporter"}
        ]
        
        result = await orchestrator.pipeline(stages, "Raw data")
        
        assert result.success
        assert result.pattern == WorkflowPattern.PIPELINE
        assert result.metadata["final_output"] == "Final report"
        
    @pytest.mark.asyncio
    async def test_hierarchical_workflow(self, orchestrator):
        # Create manager and workers
        await orchestrator.create_agent("manager", "You are a manager")
        workers = ["worker1", "worker2"]
        for w in workers:
            await orchestrator.create_agent(w, f"You are {w}")
            
        # Mock responses
        orchestrator.agents["manager"].ask = AsyncMock(
            side_effect=[
                "Worker 1: Do task A\nWorker 2: Do task B",
                "Combined results"
            ]
        )
        
        for w in workers:
            orchestrator.agents[w].ask = AsyncMock(
                return_value=f"{w} completed task"
            )
            
        result = await orchestrator.hierarchical(
            "manager",
            workers,
            "Complex project"
        )
        
        assert result.success
        assert result.pattern == WorkflowPattern.HIERARCHICAL
        assert "manager" in result.metadata
        
    @pytest.mark.asyncio
    async def test_error_handling(self, orchestrator):
        # Create agent that fails
        await orchestrator.create_agent("faulty", "Faulty agent")
        orchestrator.agents["faulty"].ask = AsyncMock(
            side_effect=Exception("Agent error")
        )
        
        # Test sequential with error
        result = await orchestrator.sequential(["faulty"], "Task")
        
        assert not result.success
        assert len(result.errors) > 0
        assert "Agent error" in result.errors[0]
```

### 5. Integration Tests
```python
# tests/integration/test_orchestrator_integration.py
import pytest
import asyncio

from src.orchestrator.core import Orchestrator
from src.orchestrator.templates import ResearchWorkflow, CodeReviewWorkflow

@pytest.mark.integration
class TestOrchestratorIntegration:
    
    @pytest.mark.asyncio
    async def test_research_workflow(self, tmp_path):
        """Test complete research workflow"""
        orchestrator = Orchestrator(base_dir=tmp_path)
        workflow = ResearchWorkflow(orchestrator)
        
        # Setup agents
        await workflow.setup()
        
        # Execute workflow
        result = await workflow.execute("Benefits of async programming")
        
        assert result.success
        assert "researcher" in result.agents
        assert "analyst" in result.agents
        assert "writer" in result.agents
        
        # Verify pipeline execution
        assert "stage_researcher" in result.results
        assert "stage_analyst" in result.results
        assert "stage_writer" in result.results
        
        await orchestrator.cleanup_all()
        
    @pytest.mark.asyncio
    async def test_concurrent_workflows(self, tmp_path):
        """Test multiple workflows running concurrently"""
        orchestrator = Orchestrator(base_dir=tmp_path)
        
        # Create multiple simple agents
        for i in range(6):
            await orchestrator.create_agent(
                f"agent_{i}",
                f"You are agent {i}"
            )
            
        # Run multiple workflows concurrently
        workflows = [
            orchestrator.sequential(["agent_0", "agent_1"], "Task 1"),
            orchestrator.parallel(["agent_2", "agent_3"], "Task 2"),
            orchestrator.sequential(["agent_4", "agent_5"], "Task 3")
        ]
        
        results = await asyncio.gather(*workflows)
        
        assert all(r.success for r in results)
        assert results[0].pattern.value == "sequential"
        assert results[1].pattern.value == "parallel"
        
        await orchestrator.cleanup_all()
```

### 6. Example Usage
```python
# examples/orchestrator_usage.py
import asyncio
from src.orchestrator.core import Orchestrator
from src.orchestrator.templates import ResearchWorkflow, BrainstormingWorkflow

async def main():
    # Create orchestrator
    orchestrator = Orchestrator()
    
    print("=== Simple Sequential Workflow ===")
    # Create agents
    await orchestrator.create_agent(
        "summarizer",
        "You are a summarizer. Create concise summaries."
    )
    await orchestrator.create_agent(
        "translator", 
        "You are a translator. Translate to Spanish."
    )
    
    # Sequential workflow
    result = await orchestrator.sequential(
        ["summarizer", "translator"],
        "Explain quantum computing in detail..."
    )
    
    print(f"Success: {result.success}")
    print(f"Final output: {result.metadata['final_output'][:200]}...")
    
    print("\n=== Research Workflow Template ===")
    # Use research workflow template
    research = ResearchWorkflow(orchestrator)
    await research.setup()
    
    research_result = await research.execute(
        "Latest developments in renewable energy"
    )
    
    print(f"Research complete: {research_result.success}")
    print(f"Stages completed: {len(research_result.results)}")
    
    print("\n=== Brainstorming Workflow ===")
    # Brainstorming workflow
    brainstorm = BrainstormingWorkflow(orchestrator)
    await brainstorm.setup()
    
    ideas_result = await brainstorm.execute(
        "New features for a task management app"
    )
    
    if ideas_result.success:
        print("Brainstorming complete!")
        print(f"Synthesized plan: {ideas_result.metadata.get('synthesized_plan', '')[:300]}...")
    
    # Cleanup
    await orchestrator.cleanup_all()

if __name__ == "__main__":
    asyncio.run(main())
```

## Success Criteria
- [ ] Orchestrator manages multiple agents effectively
- [ ] All workflow patterns implemented and tested
- [ ] Templates provide reusable workflows
- [ ] Error handling prevents cascade failures
- [ ] Concurrent workflows execute efficiently
- [ ] Resource cleanup is comprehensive
- [ ] Integration tests validate real workflows

## Next Steps
With the Orchestrator complete, Step 6 will implement the CLI interface and configuration system for user interaction.